{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\asus laptop\\appdata\\roaming\\python\\python37\\site-packages (2.31.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\asus laptop\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus laptop\\appdata\\roaming\\python\\python37\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus laptop\\appdata\\roaming\\python\\python37\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus laptop\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus laptop\\appdata\\roaming\\python\\python37\\site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\asus laptop\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from beautifulsoup4) (2.4.1)\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.890\n",
      "URL: https://www.gadgets360.com/ai/news/tsmc-shipment-sophgo-suspended-huawei-processor-6891763 - Predicted: FAKE, Actual: REAL\n",
      "URL: https://www.gadgets360.com/ai/news/tsmc-shipment-sophgo-suspended-huawei-processor-6891763 - Predicted: FAKE, Actual: FAKE\n",
      "Accuracy on URL-based data: 0.500\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# Required libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "\n",
    "# Load and preprocess dataset\n",
    "df = pd.read_csv('fake_or_real_news.csv')\n",
    "df = df.set_index('Unnamed: 0')\n",
    "y = df.label\n",
    "df = df.drop('label', axis=1)\n",
    "df\n",
    "\n",
    "# Stratified sampling to maintain class balance in train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['text'], y, test_size=0.33, random_state=53, stratify=y)\n",
    "\n",
    "# Use TF-IDF vectorizer with bigrams\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2))\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000, random_state=42, C=1)\n",
    "model.fit(tfidf_train, y_train)\n",
    "\n",
    "def fetch_article_text(url):\n",
    "    \"\"\"Fetch the main text content from a news article URL.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    paragraphs = soup.find_all('p')\n",
    "    article_text = ' '.join([para.get_text() for para in paragraphs])\n",
    "    return article_text\n",
    "\n",
    "def classify_article(url, threshold=0.4):\n",
    "    \"\"\"Classify a news article as FAKE or REAL given its URL, with a threshold adjustment.\"\"\"\n",
    "    article_text = fetch_article_text(url)\n",
    "    article_vector = tfidf_vectorizer.transform([article_text])\n",
    "    prob_fake = model.predict_proba(article_vector)[0][0]\n",
    "    return \"REAL\" if prob_fake < threshold else \"FAKE\"\n",
    "\n",
    "# Evaluate model on test set\n",
    "pred_probs = model.predict_proba(tfidf_test)\n",
    "pred = [\"REAL\" if prob[0] < 0.4 else \"FAKE\" for prob in pred_probs]\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"Accuracy on test set: {:.3f}\".format(score))\n",
    "\n",
    "# Example URL dataset with known labels\n",
    "url_data = [\n",
    "    {\"url\": \"https://www.gadgets360.com/ai/news/tsmc-shipment-sophgo-suspended-huawei-processor-6891763\", \"label\": \"REAL\"},\n",
    "    {\"url\": \"https://www.gadgets360.com/ai/news/tsmc-shipment-sophgo-suspended-huawei-processor-6891763\", \"label\": \"FAKE\"},\n",
    "    # Add more URLs with known labels\n",
    "]\n",
    "\n",
    "# Calculate accuracy for URL-based predictions and print results\n",
    "correct_predictions = 0\n",
    "\n",
    "for entry in url_data:\n",
    "    prediction = classify_article(entry[\"url\"])\n",
    "    print(f\"URL: {entry['url']} - Predicted: {prediction}, Actual: {entry['label']}\")\n",
    "    if prediction == entry[\"label\"]:\n",
    "        correct_predictions += 1\n",
    "\n",
    "url_accuracy = correct_predictions / len(url_data)\n",
    "print(f\"Accuracy on URL-based data: {url_accuracy:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
